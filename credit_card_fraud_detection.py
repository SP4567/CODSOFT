# -*- coding: utf-8 -*-
"""Credit_Card_Fraud_Detection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wdJRHy_6i2OlqPSnqueDo6GOx2Nhf_o6
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

tr = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/fraudTrain.csv')
tt = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/fraudTest.csv')

tr.head(5)

tt.head(5)

sns.countplot(x = 'is_fraud', data = tr)

sns.countplot(x = 'is_fraud', data = tt)

#from sklearn.preprocessing import OneHotEncoder
#categorical_columns = {'merchant', 'category', 'job', 'trans_num', 'street'}
#one_hot_encode = OneHotEncoder()
#encoded_cols = one_hot_encode.fit_transform(tr[categorical_columns])

#encoded_cols

tr = tr.drop(labels={'trans_date_trans_time','category', 'street'}, axis = 1)

tr.info()

tr['dob']= tr['dob'].fillna(method = 'ffill')
tr['trans_num']= tr['trans_num'].fillna(method = 'ffill')
tr['unix_time']= tr['unix_time'].fillna(method = 'ffill')
tr['merch_lat']= tr['merch_lat'].fillna(method = 'ffill')
tr['merch_long']= tr['merch_long'].fillna(method = 'ffill')
tr['is_fraud']= tr['is_fraud'].fillna(method = 'ffill')

tr.info()

tt.info()

tt['dob']= tt['dob'].fillna(method = 'ffill')
tt['trans_num']= tt['trans_num'].fillna(method = 'ffill')
tt['unix_time']= tt['unix_time'].fillna(method = 'ffill')
tt['merch_lat']= tt['merch_lat'].fillna(method = 'ffill')
tt['merch_long']= tt['merch_long'].fillna(method = 'ffill')
tt['is_fraud']= tt['is_fraud'].fillna(method = 'ffill')

tt['job']= tt['job'].fillna(method = 'ffill')
tt['city_pop']= tt['city_pop'].fillna(method = 'ffill')

tt.info()

tt = tt.drop(labels={'trans_date_trans_time','category', 'street'}, axis = 1)

tt.info()

tr.info()

selected_features = {'cc_num', 'zip', 'city_pop', 'unix_time', 'merch_lat', 'merch_long'}
X_train = tr[selected_features]
y_train = tr['is_fraud']

from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
X_train = scaler.fit_transform(X_train)

selected_features2 = {'cc_num', 'zip', 'city_pop', 'unix_time', 'merch_lat', 'merch_long'}
X_test = tt[selected_features]
y_test = tt['is_fraud']

X_test = scaler.fit_transform(X_test)

print(X_train.shape)
print(X_test.shape)
print(y_train.shape)
print(y_test.shape)

from sklearn.linear_model import LinearRegression
model1 = LinearRegression()
model1.fit(X_train, y_train)
model1.score(X_train,y_train)

from sklearn.linear_model import LogisticRegression
model2 = LogisticRegression()
model2.fit(X_train, y_train)
model2.score(X_train,y_train)

from sklearn.naive_bayes import GaussianNB
model3 = GaussianNB()
model3.fit(X_train, y_train)
model3.score(X_train,y_train)

#from sklearn.ensemble import RandomForestClassifier
#model4 = RandomForestClassifier()
#model4.fit(X_train, y_train)
#model4.score(X_train,y_train)

from sklearn.naive_bayes import GaussianNB
model4 = GaussianNB()
model4.fit(X_test, y_test)
model4.score(X_test,y_test)

from sklearn.linear_model import LogisticRegression
model5 = LogisticRegression()
model5.fit(X_test, y_test)
model5.score(X_test,y_test)

