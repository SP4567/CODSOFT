# -*- coding: utf-8 -*-
"""spam_sms_detection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1g8GfY7iedgrxD6nYHjdsxamSpRudiVlG
"""

#importing all the important libraries for the developement of the model as well as the machine learning models through the scikit learn library.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC

#importing the dataset in colab through the pandas library, with the encoding as encoding is in latin.
spam = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/spam.csv', encoding = 'latin-1')

#dataset before removing unnecessary columns.
spam

#dropping all the unnecessary columns from the dataset using the drop function.
spam = spam.drop(labels = {'Unnamed: 2',	'Unnamed: 3',	'Unnamed: 4'}, axis = 1)

#datsaset after removing unnecessary columns.
spam

#displaying first five rows of the dataset using the head function or method.
spam.head(5)

#info of the dataset.
spam.info()

#countplot of target attribute giving the count of spam sms and ham sms.
sns.countplot(x = 'v1', data = spam)

#predictor column
spam['v2']

#using the tf-idf technique to count frequency of a particular word and to check whether that word is important or not.
sample_text = ['This is the first copy.','This is the second copy.','And this is the third one.','Is this the first copy?']
vectorizer = TfidfVectorizer()
X = vectorizer.fit_transform(sample_text)

#X has been converted to sparse matrix using the tf-idf vectorizer.
X

#displaying the values of X after converting the sparse matrix to normal array.
print(X.toarray())

#displaying the features names of the demo sentence given above.
print(vectorizer.get_feature_names_out())

#now fitting the predictor attribute in the vectorizer so as to get the vectors of sms.
spam_message = vectorizer.fit_transform(spam['v2'])

#shape of sms after creating the vectors.
spam_message.shape

##displaying the features names of the sms.
print(vectorizer.get_feature_names_out())

#displaying the array
print(spam_message.toarray())

#dropping the v2 attribute that contains the sms and adding the vectorized attribute to the dataset.
spam.drop(['v2'], axis = 1, inplace = True)

#converting and adding the vectorized sms into a dataframe.
spam_ms = pd.DataFrame(spam_message.toarray())

#joining the dataframes.
spam = pd.concat([spam,spam_ms], axis = 1)

#new dataframe after combining the above two.
spam

#dropping the target attribute from the predictor variable.
X = spam.drop(labels = {'v1'}, axis = 1)

#assigning v1 attributee to the target attribute.
y = spam[['v1']]

y

#splitting the dataset into training and testing set.
X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.2)

#displaying the shape of the both training and testing dataset.
print(X_train.shape)
print(X_test.shape)
print(y_train.shape)
print(y_test.shape)

#imported LogisticRegression() model directly through the scikit learn library specified in cell number 1.
model1 = LogisticRegression()
model1.fit(X_train,y_train)
print("Training_Score:",model1.score(X_train, y_train)*100)
print("Testing_score :",model1.score(X_test, y_test)*100)

#imported RandomForestClassifier() model directly through the scikit learn library specified in cell number 1.
model2 = RandomForestClassifier()
model2.fit(X_train,y_train)
print("Training_Score:",model2.score(X_train, y_train)*100)
print("Testing_score :",model2.score(X_test, y_test)*100)

#imported GaussianNB() model directly through the scikit learn library specified in cell number 1.
model3 = GaussianNB()
model3.fit(X_train,y_train)
print("Training_Score:",model3.score(X_train, y_train)*100)
print("Testing_score :",model3.score(X_test, y_test)*100)

#imported Support vector Machine aka SVC() model directly through the scikit learn library specified in cell number 1.
model4 = SVC()
model4.fit(X_train, y_train)
print("Training_Score:",model4.score(X_train, y_train)*100)
print("Testing_score :",model4.score(X_test, y_test)*100)